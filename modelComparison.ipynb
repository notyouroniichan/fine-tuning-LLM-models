{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4lNKrnG9KF3R"
      },
      "source": [
        "**Importing quora-question-answer dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "xOKZGgPrl_Pj",
        "outputId": "f539a38f-8786-4500-d7d1-83dfe84df20d"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"hf://datasets/toughdata/quora-question-answer-dataset/Quora-QuAD.jsonl\", lines=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "3ffCvdASIgsk",
        "outputId": "86827178-72dd-4e7e-86dd-8513dc4f5bf3"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niM09L2TIj41"
      },
      "outputs": [],
      "source": [
        "df = df.dropna(subset=['question', 'answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmidXL69JS3l",
        "outputId": "e874d397-a638-49a8-bb9d-227a663b903d"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bcfdSD3QJl3j"
      },
      "source": [
        "**Data Preprocessing**\n",
        "\n",
        "* Tokenize the text\n",
        "* Remove stop words\n",
        "* Apply lemantization to reduce words to their base forms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHVk9xMxJV_l"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebEib5OvOTEV",
        "outputId": "2fc2410a-6792-40c5-d0e8-e277c9bd9990"
      },
      "outputs": [],
      "source": [
        "#downloading necessary nltk data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFxAfTC1ObhH"
      },
      "outputs": [],
      "source": [
        "#initializing stop words and lemmantizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ8WdUp7OplT"
      },
      "outputs": [],
      "source": [
        "#pre-processing text\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower()) #tokenization\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words] #stop word removal\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens] #lemmantization\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "df['processedQuestion'] = df['question'].apply(preprocess_text)\n",
        "df['processedAnswer'] = df['answer'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "-rAxaRgJOyn9",
        "outputId": "f2a8f157-e4f3-4cc8-e327-a37e505609f0"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpIpKqMLPI5I",
        "outputId": "9b015245-09d0-4d47-dd7c-4a62b372eb79"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcatl9EBRdRE"
      },
      "source": [
        "**Splitting the data into training and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBAUAiZc12sb",
        "outputId": "4b86a0b0-c99e-4465-f364-8c430c664660"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install accelerate -U\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/mlfoundations/open_lm.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUBh35TQQhw-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from open_lm.hf import *\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "#function to prepare data in order to train the models\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "datasets = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset\n",
        "})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WrfeUcXiTYdo"
      },
      "source": [
        "***Using transformers model from Huggingface to test various NLP models on our dataset***\n",
        "\n",
        "1. GPT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAukpLczShGG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, AutoModelForSeq2SeqLM\n",
        "\n",
        "modelGPT = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "tokenizerGPT = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "if tokenizerGPT.pad_token is None:\n",
        "    tokenizerGPT.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    modelGPT.resize_token_embeddings(len(tokenizerGPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4bfba9abdbc74e4cb9bfd1003948efca",
            "716b2293d4aa4e1fafeb4ad35936e62b",
            "d1075b3ce7ff4e35ab6b9f374ae42253",
            "d75e78312b8f4b968522e3a70aba39be",
            "bf94ffc51a524ab4a0fd878c234ba5ce",
            "f1111b11d4ea407ab91b204e22e59a53",
            "2add633b19e34d66a3f3c8a6aac3efe7",
            "80c7038fc4ae4ed797b6cdc384216895",
            "08fddc7d1571483fa1e7c88abe3655f4",
            "c56c7f29e7c84030a93fe4c2752ea690",
            "17140849f0f74990b7dac68c7575c9ed",
            "3fab8048736743adb144a569cdd90776",
            "cc7868f6821e4118b0e0cb532c2956fe",
            "d86faeab991c45e48f0f7fe198528e03",
            "e513067680674c38bda9f1388f9466cf",
            "3ae65f1178a84d5994139ccb29d65134",
            "ddfd1c76391a4eb58ea29cbbc10ad9bc",
            "dd324fcf53c344a2bff8c30e8b5101fe",
            "ea29afbb2e5e4837bcc65f0ce969a15b",
            "5d1d56b589ff4f67bee6838d24000f36",
            "31599d17963f49c1a8595f8db02a8783",
            "346dea3a63154957b2b322fb214d0535"
          ]
        },
        "id": "RXbqXdLnT7ng",
        "outputId": "11b8b9df-a70d-4a66-cb5b-5f901144f14a"
      },
      "outputs": [],
      "source": [
        "#tokenizing the input data\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizerGPT(examples['processedQuestion'], truncation=True, padding='max_length', max_length=256)\n",
        "    labels = tokenizerGPT(examples['processedAnswer'], truncation=True, padding='max_length', max_length=256)\n",
        "    inputs['labels'] = labels['input_ids']\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=modelGPT,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Pegasus Xsum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelpeg = AutoModelForCausalLM.from_pretrained('google/pegasus-xsum',is_decoder = True)\n",
        "tokenizerpeg = AutoTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "\n",
        "if tokenizerpeg.pad_token is None:\n",
        "    tokenizerpeg.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    modelpeg.resize_token_embeddings(len(tokenizerpeg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tokenizing the input data\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizerpeg(examples['processedQuestion'], truncation=True, padding='max_length', max_length=256)\n",
        "    labels = tokenizerpeg(examples['processedAnswer'], truncation=True, padding='max_length', max_length=256)\n",
        "    inputs['labels'] = labels['input_ids']\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=modelpeg,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. T5 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelT5 = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "tokenizerT5 = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "if tokenizerT5.pad_token is None:\n",
        "    tokenizerT5.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    modelT5.resize_token_embeddings(len(tokenizerT5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tokenizing the input data\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizerT5(examples['processedQuestion'], truncation=True, padding='max_length', max_length=256)\n",
        "    labels = tokenizerT5(examples['processedAnswer'], truncation=True, padding='max_length', max_length=256)\n",
        "    inputs['labels'] = labels['input_ids']\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=modelT5,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. BART Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelBart = AutoModelForCausalLM.from_pretrained(\"facebook/bart-base\")\n",
        "tokenizerBart = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "if tokenizerBart.pad_token is None:\n",
        "    tokenizerBart.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    modelBart.resize_token_embeddings(len(tokenizerBart))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tokenizing the input data\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizerBart(examples['processedQuestion'], truncation=True, padding='max_length', max_length=256)\n",
        "    labels = tokenizerBart(examples['processedAnswer'], truncation=True, padding='max_length', max_length=256)\n",
        "    inputs['labels'] = labels['input_ids']\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=modelBart,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Apple DCLM-Baseline-7B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelApple = AutoModelForCausalLM.from_pretrained(\"apple/DCLM-Baseline-7B\")\n",
        "tokenizerApple = AutoTokenizer.from_pretrained(\"apple/DCLM-Baseline-7B\")\n",
        "\n",
        "if tokenizerApple.pad_token is None:\n",
        "    tokenizerApple.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    modelApple.resize_token_embeddings(len(tokenizerApple))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#tokenizing the input data\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizerApple(examples['processedQuestion'], truncation=True, padding='max_length', max_length=256)\n",
        "    labels = tokenizerApple(examples['processedAnswer'], truncation=True, padding='max_length', max_length=256)\n",
        "    inputs['labels'] = labels['input_ids']\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=modelApple,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Evaluating Models and Vizualization**\n",
        "\n",
        "*On the basis of ROUGE, BLEU, and F1-Score*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#installing required libraries\n",
        "!pip install rouge-score nltk matplotlib seaborn plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#function to calculate ROUGE score\n",
        "def calculate_rouge(predictions, references):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = [scorer.score(pred, ref) for pred, ref in zip(predictions, references)]\n",
        "    return np.mean([score['rougeL'].fmeasure for score in scores])\n",
        "\n",
        "#function to calculate BLEU score\n",
        "def calculate_bleu(predictions, references):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    scores = [sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie) for pred, ref in zip(predictions, references)]\n",
        "    return np.mean(scores)\n",
        "\n",
        "#function to F1-score\n",
        "def calculate_f1(predictions, references):\n",
        "    predictions_flat = [item for sublist in predictions for item in sublist.split()]\n",
        "    references_flat = [item for sublist in references for item in sublist.split()]\n",
        "    return f1_score(references_flat, predictions_flat, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#function for model evaluation\n",
        "def evaluate_model(model, tokenizer, test_dataset):\n",
        "    predictions = []\n",
        "    references = []\n",
        "    \n",
        "    for example in test_dataset:\n",
        "        question = example['processedQuestion']\n",
        "        reference = example['processedAnswer']\n",
        "        \n",
        "        input_ids = tokenizer.encode(question, return_tensors=\"pt\")\n",
        "        output_ids = model.generate(input_ids, max_length=256, pad_token_id=tokenizer.pad_token_id)\n",
        "        \n",
        "        prediction = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "        \n",
        "        predictions.append(prediction)\n",
        "        references.append(reference)\n",
        "    \n",
        "    rouge_score = calculate_rouge(predictions, references)\n",
        "    bleu_score = calculate_bleu(predictions, references)\n",
        "    f1 = calculate_f1(predictions, references)\n",
        "    \n",
        "    return rouge_score, bleu_score, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#evaluating individual models\n",
        "\n",
        "gpt2_rouge, gpt2_bleu, gpt2_f1 = evaluate_model(modelGPT, tokenizerGPT, tokenized_datasets['validation'])\n",
        "print(f'GPT-2 - ROUGE: {gpt2_rouge}, BLEU: {gpt2_bleu}, F1: {gpt2_f1}')\n",
        "\n",
        "t5_rouge, t5_bleu, t5_f1 = evaluate_model(modelT5, tokenizerT5, tokenized_datasets['validation'])\n",
        "print(f'T5 - ROUGE: {t5_rouge}, BLEU: {t5_bleu}, F1: {t5_f1}')\n",
        "\n",
        "peg_rouge, peg_bleu, peg_f1 = evaluate_model(modelpeg, tokenizerpeg, tokenized_datasets['validation'])\n",
        "print(f'peg - ROUGE: {peg_rouge}, BLEU: {peg_bleu}, F1: {peg_f1}')\n",
        "\n",
        "Bart_rouge, Bart_bleu, Bart_f1 = evaluate_model(modelBart, tokenizerBart, tokenized_datasets['validation'])\n",
        "print(f'Bart - ROUGE: {Bart_rouge}, BLEU: {Bart_bleu}, F1: {Bart_f1}')\n",
        "\n",
        "Apple_rouge, Apple_bleu, Apple_f1 = evaluate_model(modelApple, tokenizerApple, tokenized_datasets['validation'])\n",
        "print(f'Apple - ROUGE: {Apple_rouge}, BLEU: {Apple_bleu}, F1: {Apple_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#vizualization of data distribution\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "# Data Distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['processedQuestion'].apply(len), bins=50, kde=True)\n",
        "plt.title('Distribution of Question Lengths')\n",
        "plt.xlabel('Length of Questions')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "performance_data = {\n",
        "    'Model': ['GPT','T5','Pegasus','BART','DCLM-Baseline-7B'],\n",
        "    'ROUGE': [gpt2_rouge,t5_rouge,peg_rouge,Bart_rouge,Apple_rouge],\n",
        "    'BLEU': [gpt2_bleu,t5_bleu,peg_bleu,Bart_bleu,Apple_bleu],\n",
        "    'F1-Score': [gpt2_f1,t5_f1,peg_f1,Bart_f1,Apple_f1]\n",
        "}\n",
        "\n",
        "performance_df = pd.DataFrame(performance_data)\n",
        "\n",
        "fig = px.bar(performance_df, x='Model', y=['ROUGE', 'BLEU', 'F1-Score'], barmode='group',\n",
        "             title='Model Performance Comparison')\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08fddc7d1571483fa1e7c88abe3655f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17140849f0f74990b7dac68c7575c9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2add633b19e34d66a3f3c8a6aac3efe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31599d17963f49c1a8595f8db02a8783": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "346dea3a63154957b2b322fb214d0535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ae65f1178a84d5994139ccb29d65134": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fab8048736743adb144a569cdd90776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc7868f6821e4118b0e0cb532c2956fe",
              "IPY_MODEL_d86faeab991c45e48f0f7fe198528e03",
              "IPY_MODEL_e513067680674c38bda9f1388f9466cf"
            ],
            "layout": "IPY_MODEL_3ae65f1178a84d5994139ccb29d65134"
          }
        },
        "4bfba9abdbc74e4cb9bfd1003948efca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_716b2293d4aa4e1fafeb4ad35936e62b",
              "IPY_MODEL_d1075b3ce7ff4e35ab6b9f374ae42253",
              "IPY_MODEL_d75e78312b8f4b968522e3a70aba39be"
            ],
            "layout": "IPY_MODEL_bf94ffc51a524ab4a0fd878c234ba5ce"
          }
        },
        "5d1d56b589ff4f67bee6838d24000f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "716b2293d4aa4e1fafeb4ad35936e62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1111b11d4ea407ab91b204e22e59a53",
            "placeholder": "​",
            "style": "IPY_MODEL_2add633b19e34d66a3f3c8a6aac3efe7",
            "value": "Map: 100%"
          }
        },
        "80c7038fc4ae4ed797b6cdc384216895": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf94ffc51a524ab4a0fd878c234ba5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56c7f29e7c84030a93fe4c2752ea690": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7868f6821e4118b0e0cb532c2956fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddfd1c76391a4eb58ea29cbbc10ad9bc",
            "placeholder": "​",
            "style": "IPY_MODEL_dd324fcf53c344a2bff8c30e8b5101fe",
            "value": "Map: 100%"
          }
        },
        "d1075b3ce7ff4e35ab6b9f374ae42253": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c7038fc4ae4ed797b6cdc384216895",
            "max": 45121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08fddc7d1571483fa1e7c88abe3655f4",
            "value": 45121
          }
        },
        "d75e78312b8f4b968522e3a70aba39be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56c7f29e7c84030a93fe4c2752ea690",
            "placeholder": "​",
            "style": "IPY_MODEL_17140849f0f74990b7dac68c7575c9ed",
            "value": " 45121/45121 [00:37&lt;00:00, 1276.93 examples/s]"
          }
        },
        "d86faeab991c45e48f0f7fe198528e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea29afbb2e5e4837bcc65f0ce969a15b",
            "max": 11281,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d1d56b589ff4f67bee6838d24000f36",
            "value": 11281
          }
        },
        "dd324fcf53c344a2bff8c30e8b5101fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddfd1c76391a4eb58ea29cbbc10ad9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e513067680674c38bda9f1388f9466cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31599d17963f49c1a8595f8db02a8783",
            "placeholder": "​",
            "style": "IPY_MODEL_346dea3a63154957b2b322fb214d0535",
            "value": " 11281/11281 [00:07&lt;00:00, 1621.01 examples/s]"
          }
        },
        "ea29afbb2e5e4837bcc65f0ce969a15b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1111b11d4ea407ab91b204e22e59a53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
